<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="458" onload="init(evt)" viewBox="0 0 1200 458" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:fg="http://github.com/jonhoo/inferno"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#matched { text-anchor:end; }
#search { text-anchor:end; opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[
        var nametype = 'Function:';
        var fontsize = 12;
        var fontwidth = 0.59;
        var xpad = 10;
        var inverted = true;
        var searchcolor = 'rgb(230,0,230)';
        var fluiddrawing = true;
        var truncate_text_right = false;
    ]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    total_samples = parseInt(frames.attributes.total_samples.value);
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[*|x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad;
            matchedtxt.attributes.x.value = svgWidth - xpad;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
            if (!isEdge) {
                svg.removeAttribute("viewBox");
            }
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes["fg:x"]) {
            var params = get_params()
            params.x = el.attributes["fg:x"].value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["fg:orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("fg:orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["fg:orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["fg:orig_" + attr].value;
    e.removeAttribute("fg:orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * parseInt(e.attributes["fg:x"].value) / total_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / total_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, zoomed_width_samples) {
    if (e.tagName == "text") {
        var parent_x = parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value);
        e.attributes.x.value = format_percent(parent_x + (100 * 3 / frames.attributes.width.value));
    } else if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * (parseInt(e.attributes["fg:x"].value) - x) / zoomed_width_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / zoomed_width_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, zoomed_width_samples);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseInt(attr["fg:w"].value);
    var xmin = parseInt(attr["fg:x"].value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseInt(a["fg:x"].value);
        var ew = parseInt(a["fg:w"].value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, width);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        // Skip over frames which are either not visible, or below the zoomed-to frame
        if (e.classList.contains("hide") || e.classList.contains("parent")) {
            continue;
        }
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseInt(rect.attributes["fg:w"].value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseInt(rect.attributes["fg:x"].value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    for (var k in keys) {
        var x = parseInt(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="458" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy record -p 11947 -d 30 -o nextword_ds.svg</text><text id="details" x="10" y="40.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1190" y="24.00">Search</text><text id="matched" x="1190" y="447.00"> </text><svg id="frames" x="10" width="1180" total_samples="2999"><g><title>Eval (model.py:311) (7 samples, 0.23%)</title><rect x="0.1667%" y="100" width="0.2334%" height="15" fill="rgb(227,0,7)" fg:x="5" fg:w="7"/><text x="0.4167%" y="110.50"></text></g><g><title>is_adult_query (model.py:216) (6 samples, 0.20%)</title><rect x="0.2001%" y="116" width="0.2001%" height="15" fill="rgb(217,0,24)" fg:x="6" fg:w="6"/><text x="0.4501%" y="126.50"></text></g><g><title>generate_ngrams (model.py:177) (4 samples, 0.13%)</title><rect x="0.2668%" y="132" width="0.1334%" height="15" fill="rgb(221,193,54)" fg:x="8" fg:w="4"/><text x="0.5168%" y="142.50"></text></g><g><title>tokenize (transformers/tokenization_utils.py:516) (4 samples, 0.13%)</title><rect x="0.7336%" y="196" width="0.1334%" height="15" fill="rgb(248,212,6)" fg:x="22" fg:w="4"/><text x="0.9836%" y="206.50"></text></g><g><title>_tokenize (transformers/models/gpt2/tokenization_gpt2.py:248) (6 samples, 0.20%)</title><rect x="0.8670%" y="212" width="0.2001%" height="15" fill="rgb(208,68,35)" fg:x="26" fg:w="6"/><text x="1.1170%" y="222.50"></text></g><g><title>findall (regex/regex.py:338) (3 samples, 0.10%)</title><rect x="0.9670%" y="228" width="0.1000%" height="15" fill="rgb(232,128,0)" fg:x="29" fg:w="3"/><text x="1.2170%" y="238.50"></text></g><g><title>_tokenize (transformers/models/gpt2/tokenization_gpt2.py:250) (3 samples, 0.10%)</title><rect x="1.0670%" y="212" width="0.1000%" height="15" fill="rgb(207,160,47)" fg:x="32" fg:w="3"/><text x="1.3170%" y="222.50"></text></g><g><title>bpe (transformers/models/gpt2/tokenization_gpt2.py:213) (7 samples, 0.23%)</title><rect x="1.2004%" y="228" width="0.2334%" height="15" fill="rgb(228,23,34)" fg:x="36" fg:w="7"/><text x="1.4504%" y="238.50"></text></g><g><title>&lt;lambda&gt; (transformers/models/gpt2/tokenization_gpt2.py:213) (5 samples, 0.17%)</title><rect x="1.2671%" y="244" width="0.1667%" height="15" fill="rgb(218,30,26)" fg:x="38" fg:w="5"/><text x="1.5171%" y="254.50"></text></g><g><title>get_input_ids (transformers/tokenization_utils.py:615) (33 samples, 1.10%)</title><rect x="0.6335%" y="180" width="1.1004%" height="15" fill="rgb(220,122,19)" fg:x="19" fg:w="33"/><text x="0.8835%" y="190.50"></text></g><g><title>tokenize (transformers/tokenization_utils.py:546) (26 samples, 0.87%)</title><rect x="0.8670%" y="196" width="0.8670%" height="15" fill="rgb(250,228,42)" fg:x="26" fg:w="26"/><text x="1.1170%" y="206.50"></text></g><g><title>_tokenize (transformers/models/gpt2/tokenization_gpt2.py:252) (17 samples, 0.57%)</title><rect x="1.1671%" y="212" width="0.5669%" height="15" fill="rgb(240,193,28)" fg:x="35" fg:w="17"/><text x="1.4171%" y="222.50"></text></g><g><title>bpe (transformers/models/gpt2/tokenization_gpt2.py:240) (5 samples, 0.17%)</title><rect x="1.5672%" y="228" width="0.1667%" height="15" fill="rgb(216,20,37)" fg:x="47" fg:w="5"/><text x="1.8172%" y="238.50"></text></g><g><title>get_pairs (transformers/models/gpt2/tokenization_gpt2.py:99) (3 samples, 0.10%)</title><rect x="1.6339%" y="244" width="0.1000%" height="15" fill="rgb(206,188,39)" fg:x="49" fg:w="3"/><text x="1.8839%" y="254.50"></text></g><g><title>_encode_plus (transformers/tokenization_utils.py:646) (35 samples, 1.17%)</title><rect x="0.6002%" y="164" width="1.1671%" height="15" fill="rgb(217,207,13)" fg:x="18" fg:w="35"/><text x="0.8502%" y="174.50"></text></g><g><title>run_generation (deepspeed_inference.py:108) (44 samples, 1.47%)</title><rect x="0.4668%" y="116" width="1.4672%" height="15" fill="rgb(231,73,38)" fg:x="14" fg:w="44"/><text x="0.7168%" y="126.50"></text></g><g><title>encode (transformers/tokenization_utils_base.py:2227) (41 samples, 1.37%)</title><rect x="0.5669%" y="132" width="1.3671%" height="15" fill="rgb(225,20,46)" fg:x="17" fg:w="41"/><text x="0.8169%" y="142.50"></text></g><g><title>encode_plus (transformers/tokenization_utils_base.py:2566) (40 samples, 1.33%)</title><rect x="0.6002%" y="148" width="1.3338%" height="15" fill="rgb(210,31,41)" fg:x="18" fg:w="40"/><text x="0.8502%" y="158.50"></text></g><g><title>_encode_plus (transformers/tokenization_utils.py:665) (4 samples, 0.13%)</title><rect x="1.8006%" y="164" width="0.1334%" height="15" fill="rgb(221,200,47)" fg:x="54" fg:w="4"/><text x="2.0506%" y="174.50"></text></g><g><title>run_generation (deepspeed_inference.py:131) (5 samples, 0.17%)</title><rect x="1.9673%" y="116" width="0.1667%" height="15" fill="rgb(226,26,5)" fg:x="59" fg:w="5"/><text x="2.2173%" y="126.50"></text></g><g><title>run_generation (deepspeed_inference.py:132) (11 samples, 0.37%)</title><rect x="2.1340%" y="116" width="0.3668%" height="15" fill="rgb(249,33,26)" fg:x="64" fg:w="11"/><text x="2.3840%" y="126.50"></text></g><g><title>get_mask (startwith_prefix_match.py:100) (40 samples, 1.33%)</title><rect x="2.6009%" y="180" width="1.3338%" height="15" fill="rgb(235,183,28)" fg:x="78" fg:w="40"/><text x="2.8509%" y="190.50"></text></g><g><title>&lt;listcomp&gt; (startwith_prefix_match.py:100) (40 samples, 1.33%)</title><rect x="2.6009%" y="196" width="1.3338%" height="15" fill="rgb(221,5,38)" fg:x="78" fg:w="40"/><text x="2.8509%" y="206.50"></text></g><g><title>get_mask (startwith_prefix_match.py:161) (15 samples, 0.50%)</title><rect x="3.9346%" y="180" width="0.5002%" height="15" fill="rgb(247,18,42)" fg:x="118" fg:w="15"/><text x="4.1846%" y="190.50"></text></g><g><title>get_mask (startwith_prefix_match.py:165) (3 samples, 0.10%)</title><rect x="4.4348%" y="180" width="0.1000%" height="15" fill="rgb(241,131,45)" fg:x="133" fg:w="3"/><text x="4.6848%" y="190.50"></text></g><g><title>__call__ (startwith_prefix_match.py:182) (63 samples, 2.10%)</title><rect x="2.5675%" y="148" width="2.1007%" height="15" fill="rgb(249,31,29)" fg:x="77" fg:w="63"/><text x="2.8175%" y="158.50">_..</text></g><g><title>&lt;listcomp&gt; (startwith_prefix_match.py:182) (63 samples, 2.10%)</title><rect x="2.5675%" y="164" width="2.1007%" height="15" fill="rgb(225,111,53)" fg:x="77" fg:w="63"/><text x="2.8175%" y="174.50">&lt;..</text></g><g><title>__call__ (startwith_prefix_match.py:183) (3 samples, 0.10%)</title><rect x="4.6682%" y="148" width="0.1000%" height="15" fill="rgb(238,160,17)" fg:x="140" fg:w="3"/><text x="4.9182%" y="158.50"></text></g><g><title>run_generation (deepspeed_inference.py:134) (77 samples, 2.57%)</title><rect x="2.5008%" y="116" width="2.5675%" height="15" fill="rgb(214,148,48)" fg:x="75" fg:w="77"/><text x="2.7508%" y="126.50">ru..</text></g><g><title>__call__ (startwith_prefix_match.py:46) (77 samples, 2.57%)</title><rect x="2.5008%" y="132" width="2.5675%" height="15" fill="rgb(232,36,49)" fg:x="75" fg:w="77"/><text x="2.7508%" y="142.50">__..</text></g><g><title>__call__ (startwith_prefix_match.py:184) (9 samples, 0.30%)</title><rect x="4.7683%" y="148" width="0.3001%" height="15" fill="rgb(209,103,24)" fg:x="143" fg:w="9"/><text x="5.0183%" y="158.50"></text></g><g><title>run_generation (deepspeed_inference.py:136) (9 samples, 0.30%)</title><rect x="5.0684%" y="116" width="0.3001%" height="15" fill="rgb(229,88,8)" fg:x="152" fg:w="9"/><text x="5.3184%" y="126.50"></text></g><g><title>deepcopy (copy.py:150) (6 samples, 0.20%)</title><rect x="5.5018%" y="164" width="0.2001%" height="15" fill="rgb(213,181,19)" fg:x="165" fg:w="6"/><text x="5.7518%" y="174.50"></text></g><g><title>_deepcopy_dict (copy.py:241) (5 samples, 0.17%)</title><rect x="5.5352%" y="180" width="0.1667%" height="15" fill="rgb(254,191,54)" fg:x="166" fg:w="5"/><text x="5.7852%" y="190.50"></text></g><g><title>_reconstruct (copy.py:281) (7 samples, 0.23%)</title><rect x="5.5018%" y="148" width="0.2334%" height="15" fill="rgb(241,83,37)" fg:x="165" fg:w="7"/><text x="5.7518%" y="158.50"></text></g><g><title>run_generation (deepspeed_inference.py:138) (12 samples, 0.40%)</title><rect x="5.3685%" y="116" width="0.4001%" height="15" fill="rgb(233,36,39)" fg:x="161" fg:w="12"/><text x="5.6185%" y="126.50"></text></g><g><title>deepcopy (copy.py:180) (9 samples, 0.30%)</title><rect x="5.4685%" y="132" width="0.3001%" height="15" fill="rgb(226,3,54)" fg:x="164" fg:w="9"/><text x="5.7185%" y="142.50"></text></g><g><title>generate_stream (generator.py:533) (11 samples, 0.37%)</title><rect x="6.0687%" y="148" width="0.3668%" height="15" fill="rgb(245,192,40)" fg:x="182" fg:w="11"/><text x="6.3187%" y="158.50"></text></g><g><title>generate_stream (generator.py:553) (6 samples, 0.20%)</title><rect x="6.4688%" y="148" width="0.2001%" height="15" fill="rgb(238,167,29)" fg:x="194" fg:w="6"/><text x="6.7188%" y="158.50"></text></g><g><title>generate_stream (generator.py:556) (12 samples, 0.40%)</title><rect x="6.6689%" y="148" width="0.4001%" height="15" fill="rgb(232,182,51)" fg:x="200" fg:w="12"/><text x="6.9189%" y="158.50"></text></g><g><title>generate_stream (generator.py:576) (6 samples, 0.20%)</title><rect x="7.0690%" y="148" width="0.2001%" height="15" fill="rgb(231,60,39)" fg:x="212" fg:w="6"/><text x="7.3190%" y="158.50"></text></g><g><title>call_model (generator.py:482) (4 samples, 0.13%)</title><rect x="7.3691%" y="164" width="0.1334%" height="15" fill="rgb(208,69,12)" fg:x="221" fg:w="4"/><text x="7.6191%" y="174.50"></text></g><g><title>preprocess_inputs (wrapper.py:13) (28 samples, 0.93%)</title><rect x="7.9693%" y="212" width="0.9336%" height="15" fill="rgb(235,93,37)" fg:x="239" fg:w="28"/><text x="8.2193%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:17) (46 samples, 1.53%)</title><rect x="8.9030%" y="212" width="1.5338%" height="15" fill="rgb(213,116,39)" fg:x="267" fg:w="46"/><text x="9.1530%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:21) (44 samples, 1.47%)</title><rect x="10.4368%" y="212" width="1.4672%" height="15" fill="rgb(222,207,29)" fg:x="313" fg:w="44"/><text x="10.6868%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:24) (46 samples, 1.53%)</title><rect x="11.9040%" y="212" width="1.5338%" height="15" fill="rgb(206,96,30)" fg:x="357" fg:w="46"/><text x="12.1540%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:25) (37 samples, 1.23%)</title><rect x="13.4378%" y="212" width="1.2337%" height="15" fill="rgb(218,138,4)" fg:x="403" fg:w="37"/><text x="13.6878%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:30) (28 samples, 0.93%)</title><rect x="14.7049%" y="212" width="0.9336%" height="15" fill="rgb(250,191,14)" fg:x="441" fg:w="28"/><text x="14.9549%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:31) (21 samples, 0.70%)</title><rect x="15.6385%" y="212" width="0.7002%" height="15" fill="rgb(239,60,40)" fg:x="469" fg:w="21"/><text x="15.8885%" y="222.50"></text></g><g><title>__iter__ (torch/tensor.py:586) (5 samples, 0.17%)</title><rect x="16.4722%" y="228" width="0.1667%" height="15" fill="rgb(206,27,48)" fg:x="494" fg:w="5"/><text x="16.7222%" y="238.50"></text></g><g><title>preprocess_inputs (wrapper.py:32) (19 samples, 0.63%)</title><rect x="16.3388%" y="212" width="0.6335%" height="15" fill="rgb(225,35,8)" fg:x="490" fg:w="19"/><text x="16.5888%" y="222.50"></text></g><g><title>__iter__ (torch/tensor.py:591) (10 samples, 0.33%)</title><rect x="16.6389%" y="228" width="0.3334%" height="15" fill="rgb(250,213,24)" fg:x="499" fg:w="10"/><text x="16.8889%" y="238.50"></text></g><g><title>preprocess_inputs (wrapper.py:33) (20 samples, 0.67%)</title><rect x="16.9723%" y="212" width="0.6669%" height="15" fill="rgb(247,123,22)" fg:x="509" fg:w="20"/><text x="17.2223%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:34) (423 samples, 14.10%)</title><rect x="17.6392%" y="212" width="14.1047%" height="15" fill="rgb(231,138,38)" fg:x="529" fg:w="423"/><text x="17.8892%" y="222.50">preprocess_inputs (wr..</text></g><g><title>preprocess_inputs (wrapper.py:37) (4 samples, 0.13%)</title><rect x="31.7773%" y="212" width="0.1334%" height="15" fill="rgb(231,145,46)" fg:x="953" fg:w="4"/><text x="32.0273%" y="222.50"></text></g><g><title>preprocess_inputs (wrapper.py:38) (3 samples, 0.10%)</title><rect x="31.9106%" y="212" width="0.1000%" height="15" fill="rgb(251,118,11)" fg:x="957" fg:w="3"/><text x="32.1606%" y="222.50"></text></g><g><title>forward (wrapper.py:65) (743 samples, 24.77%)</title><rect x="7.8693%" y="196" width="24.7749%" height="15" fill="rgb(217,147,25)" fg:x="236" fg:w="743"/><text x="8.1193%" y="206.50">forward (wrapper.py:65)</text></g><g><title>preprocess_inputs (wrapper.py:50) (19 samples, 0.63%)</title><rect x="32.0107%" y="212" width="0.6335%" height="15" fill="rgb(247,81,37)" fg:x="960" fg:w="19"/><text x="32.2607%" y="222.50"></text></g><g><title>&lt;genexpr&gt; (wrapper.py:50) (16 samples, 0.53%)</title><rect x="32.1107%" y="228" width="0.5335%" height="15" fill="rgb(209,12,38)" fg:x="963" fg:w="16"/><text x="32.3607%" y="238.50"></text></g><g><title>&lt;genexpr&gt; (wrapper.py:49) (13 samples, 0.43%)</title><rect x="32.2107%" y="244" width="0.4335%" height="15" fill="rgb(227,1,9)" fg:x="966" fg:w="13"/><text x="32.4607%" y="254.50"></text></g><g><title>forward (wrapper.py:67) (6 samples, 0.20%)</title><rect x="32.6442%" y="196" width="0.2001%" height="15" fill="rgb(248,47,43)" fg:x="979" fg:w="6"/><text x="32.8942%" y="206.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:771) (8 samples, 0.27%)</title><rect x="34.2447%" y="292" width="0.2668%" height="15" fill="rgb(221,10,30)" fg:x="1027" fg:w="8"/><text x="34.4947%" y="302.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:784) (4 samples, 0.13%)</title><rect x="34.5115%" y="292" width="0.1334%" height="15" fill="rgb(210,229,1)" fg:x="1035" fg:w="4"/><text x="34.7615%" y="302.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:805) (8 samples, 0.27%)</title><rect x="34.6782%" y="292" width="0.2668%" height="15" fill="rgb(222,148,37)" fg:x="1040" fg:w="8"/><text x="34.9282%" y="302.50"></text></g><g><title>_named_members (torch/nn/modules/module.py:1231) (3 samples, 0.10%)</title><rect x="35.8786%" y="372" width="0.1000%" height="15" fill="rgb(234,67,33)" fg:x="1076" fg:w="3"/><text x="36.1286%" y="382.50"></text></g><g><title>parameters (torch/nn/modules/module.py:1261) (8 samples, 0.27%)</title><rect x="35.8119%" y="340" width="0.2668%" height="15" fill="rgb(247,98,35)" fg:x="1074" fg:w="8"/><text x="36.0619%" y="350.50"></text></g><g><title>named_parameters (torch/nn/modules/module.py:1287) (6 samples, 0.20%)</title><rect x="35.8786%" y="356" width="0.2001%" height="15" fill="rgb(247,138,52)" fg:x="1076" fg:w="6"/><text x="36.1286%" y="366.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:812) (35 samples, 1.17%)</title><rect x="34.9450%" y="292" width="1.1671%" height="15" fill="rgb(213,79,30)" fg:x="1048" fg:w="35"/><text x="35.1950%" y="302.50"></text></g><g><title>dtype (transformers/modeling_utils.py:487) (10 samples, 0.33%)</title><rect x="35.7786%" y="308" width="0.3334%" height="15" fill="rgb(246,177,23)" fg:x="1073" fg:w="10"/><text x="36.0286%" y="318.50"></text></g><g><title>get_parameter_dtype (transformers/modeling_utils.py:143) (9 samples, 0.30%)</title><rect x="35.8119%" y="324" width="0.3001%" height="15" fill="rgb(230,62,27)" fg:x="1074" fg:w="9"/><text x="36.0619%" y="334.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:813) (43 samples, 1.43%)</title><rect x="36.1120%" y="292" width="1.4338%" height="15" fill="rgb(216,154,8)" fg:x="1083" fg:w="43"/><text x="36.3620%" y="302.50"></text></g><g><title>__rsub__ (torch/tensor.py:528) (27 samples, 0.90%)</title><rect x="36.6455%" y="308" width="0.9003%" height="15" fill="rgb(244,35,45)" fg:x="1099" fg:w="27"/><text x="36.8955%" y="318.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:817) (4 samples, 0.13%)</title><rect x="37.5458%" y="292" width="0.1334%" height="15" fill="rgb(251,115,12)" fg:x="1126" fg:w="4"/><text x="37.7958%" y="302.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (24 samples, 0.80%)</title><rect x="38.0794%" y="308" width="0.8003%" height="15" fill="rgb(240,54,50)" fg:x="1142" fg:w="24"/><text x="38.3294%" y="318.50"></text></g><g><title>forward (torch/nn/modules/sparse.py:147) (22 samples, 0.73%)</title><rect x="38.1460%" y="324" width="0.7336%" height="15" fill="rgb(233,84,52)" fg:x="1144" fg:w="22"/><text x="38.3960%" y="334.50"></text></g><g><title>embedding (torch/nn/functional.py:1913) (21 samples, 0.70%)</title><rect x="38.1794%" y="340" width="0.7002%" height="15" fill="rgb(207,117,47)" fg:x="1145" fg:w="21"/><text x="38.4294%" y="350.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:833) (38 samples, 1.27%)</title><rect x="37.6792%" y="292" width="1.2671%" height="15" fill="rgb(249,43,39)" fg:x="1130" fg:w="38"/><text x="37.9292%" y="302.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (21 samples, 0.70%)</title><rect x="39.0797%" y="308" width="0.7002%" height="15" fill="rgb(209,38,44)" fg:x="1172" fg:w="21"/><text x="39.3297%" y="318.50"></text></g><g><title>forward (torch/nn/modules/sparse.py:147) (20 samples, 0.67%)</title><rect x="39.1130%" y="324" width="0.6669%" height="15" fill="rgb(236,212,23)" fg:x="1173" fg:w="20"/><text x="39.3630%" y="334.50"></text></g><g><title>embedding (torch/nn/functional.py:1913) (19 samples, 0.63%)</title><rect x="39.1464%" y="340" width="0.6335%" height="15" fill="rgb(242,79,21)" fg:x="1174" fg:w="19"/><text x="39.3964%" y="350.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:834) (28 samples, 0.93%)</title><rect x="38.9463%" y="292" width="0.9336%" height="15" fill="rgb(211,96,35)" fg:x="1168" fg:w="28"/><text x="39.1963%" y="302.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:892) (3 samples, 0.10%)</title><rect x="39.7799%" y="308" width="0.1000%" height="15" fill="rgb(253,215,40)" fg:x="1193" fg:w="3"/><text x="40.0299%" y="318.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:835) (19 samples, 0.63%)</title><rect x="39.8800%" y="292" width="0.6335%" height="15" fill="rgb(211,81,21)" fg:x="1196" fg:w="19"/><text x="40.1300%" y="302.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (7 samples, 0.23%)</title><rect x="40.6802%" y="308" width="0.2334%" height="15" fill="rgb(208,190,38)" fg:x="1220" fg:w="7"/><text x="40.9302%" y="318.50"></text></g><g><title>forward (torch/nn/modules/dropout.py:58) (7 samples, 0.23%)</title><rect x="40.6802%" y="324" width="0.2334%" height="15" fill="rgb(235,213,38)" fg:x="1220" fg:w="7"/><text x="40.9302%" y="334.50"></text></g><g><title>dropout (torch/nn/functional.py:1076) (7 samples, 0.23%)</title><rect x="40.6802%" y="340" width="0.2334%" height="15" fill="rgb(237,122,38)" fg:x="1220" fg:w="7"/><text x="40.9302%" y="350.50"></text></g><g><title>__getattr__ (torch/_VF.py:26) (3 samples, 0.10%)</title><rect x="40.8136%" y="356" width="0.1000%" height="15" fill="rgb(244,218,35)" fg:x="1224" fg:w="3"/><text x="41.0636%" y="366.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:841) (13 samples, 0.43%)</title><rect x="40.5135%" y="292" width="0.4335%" height="15" fill="rgb(240,68,47)" fg:x="1215" fg:w="13"/><text x="40.7635%" y="302.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:849) (9 samples, 0.30%)</title><rect x="40.9470%" y="292" width="0.3001%" height="15" fill="rgb(210,16,53)" fg:x="1228" fg:w="9"/><text x="41.1970%" y="302.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (33 samples, 1.10%)</title><rect x="41.6472%" y="340" width="1.1004%" height="15" fill="rgb(235,124,12)" fg:x="1249" fg:w="33"/><text x="41.8972%" y="350.50"></text></g><g><title>forward (torch/nn/modules/normalization.py:171) (32 samples, 1.07%)</title><rect x="41.6806%" y="356" width="1.0670%" height="15" fill="rgb(224,169,11)" fg:x="1250" fg:w="32"/><text x="41.9306%" y="366.50"></text></g><g><title>layer_norm (torch/nn/functional.py:2202) (29 samples, 0.97%)</title><rect x="41.7806%" y="372" width="0.9670%" height="15" fill="rgb(250,166,2)" fg:x="1253" fg:w="29"/><text x="42.0306%" y="382.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:394) (39 samples, 1.30%)</title><rect x="41.5138%" y="324" width="1.3004%" height="15" fill="rgb(242,216,29)" fg:x="1245" fg:w="39"/><text x="41.7638%" y="334.50"></text></g><g><title>forward (transformers/modeling_utils.py:2326) (4 samples, 0.13%)</title><rect x="43.0143%" y="388" width="0.1334%" height="15" fill="rgb(230,116,27)" fg:x="1290" fg:w="4"/><text x="43.2643%" y="398.50"></text></g><g><title>forward (transformers/modeling_utils.py:2327) (44 samples, 1.47%)</title><rect x="43.1477%" y="388" width="1.4672%" height="15" fill="rgb(228,99,48)" fg:x="1294" fg:w="44"/><text x="43.3977%" y="398.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (52 samples, 1.73%)</title><rect x="42.9810%" y="372" width="1.7339%" height="15" fill="rgb(253,11,6)" fg:x="1289" fg:w="52"/><text x="43.2310%" y="382.50"></text></g><g><title>forward (transformers/modeling_utils.py:2328) (3 samples, 0.10%)</title><rect x="44.6149%" y="388" width="0.1000%" height="15" fill="rgb(247,143,39)" fg:x="1338" fg:w="3"/><text x="44.8649%" y="398.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:317) (66 samples, 2.20%)</title><rect x="42.9143%" y="356" width="2.2007%" height="15" fill="rgb(236,97,10)" fg:x="1287" fg:w="66"/><text x="43.1643%" y="366.50">f..</text></g><g><title>split (torch/tensor.py:491) (7 samples, 0.23%)</title><rect x="44.8816%" y="372" width="0.2334%" height="15" fill="rgb(233,208,19)" fg:x="1346" fg:w="7"/><text x="45.1316%" y="382.50"></text></g><g><title>_split_heads (transformers/models/gpt2/modeling_gpt2.py:283) (7 samples, 0.23%)</title><rect x="45.1150%" y="372" width="0.2334%" height="15" fill="rgb(216,164,2)" fg:x="1353" fg:w="7"/><text x="45.3650%" y="382.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:319) (11 samples, 0.37%)</title><rect x="45.1150%" y="356" width="0.3668%" height="15" fill="rgb(220,129,5)" fg:x="1353" fg:w="11"/><text x="45.3650%" y="366.50"></text></g><g><title>_split_heads (transformers/models/gpt2/modeling_gpt2.py:285) (3 samples, 0.10%)</title><rect x="45.3818%" y="372" width="0.1000%" height="15" fill="rgb(242,17,10)" fg:x="1361" fg:w="3"/><text x="45.6318%" y="382.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:320) (4 samples, 0.13%)</title><rect x="45.4818%" y="356" width="0.1334%" height="15" fill="rgb(242,107,0)" fg:x="1364" fg:w="4"/><text x="45.7318%" y="366.50"></text></g><g><title>_split_heads (transformers/models/gpt2/modeling_gpt2.py:285) (3 samples, 0.10%)</title><rect x="45.5152%" y="372" width="0.1000%" height="15" fill="rgb(251,28,31)" fg:x="1365" fg:w="3"/><text x="45.7652%" y="382.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:325) (18 samples, 0.60%)</title><rect x="45.6485%" y="356" width="0.6002%" height="15" fill="rgb(233,223,10)" fg:x="1369" fg:w="18"/><text x="45.8985%" y="366.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:326) (12 samples, 0.40%)</title><rect x="46.2487%" y="356" width="0.4001%" height="15" fill="rgb(215,21,27)" fg:x="1387" fg:w="12"/><text x="46.4987%" y="366.50"></text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:193) (69 samples, 2.30%)</title><rect x="46.7156%" y="372" width="2.3008%" height="15" fill="rgb(232,23,21)" fg:x="1401" fg:w="69"/><text x="46.9656%" y="382.50">_..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:196) (22 samples, 0.73%)</title><rect x="49.0497%" y="372" width="0.7336%" height="15" fill="rgb(244,5,23)" fg:x="1471" fg:w="22"/><text x="49.2997%" y="382.50"></text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:205) (23 samples, 0.77%)</title><rect x="49.8833%" y="372" width="0.7669%" height="15" fill="rgb(226,81,46)" fg:x="1496" fg:w="23"/><text x="50.1333%" y="382.50"></text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:206) (26 samples, 0.87%)</title><rect x="50.6502%" y="372" width="0.8670%" height="15" fill="rgb(247,70,30)" fg:x="1519" fg:w="26"/><text x="50.9002%" y="382.50"></text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:210) (15 samples, 0.50%)</title><rect x="51.5172%" y="372" width="0.5002%" height="15" fill="rgb(212,68,19)" fg:x="1545" fg:w="15"/><text x="51.7672%" y="382.50"></text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:212) (13 samples, 0.43%)</title><rect x="52.0173%" y="372" width="0.4335%" height="15" fill="rgb(240,187,13)" fg:x="1560" fg:w="13"/><text x="52.2673%" y="382.50"></text></g><g><title>softmax (torch/nn/functional.py:1583) (12 samples, 0.40%)</title><rect x="52.0507%" y="388" width="0.4001%" height="15" fill="rgb(223,113,26)" fg:x="1561" fg:w="12"/><text x="52.3007%" y="398.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (10 samples, 0.33%)</title><rect x="52.7843%" y="388" width="0.3334%" height="15" fill="rgb(206,192,2)" fg:x="1583" fg:w="10"/><text x="53.0343%" y="398.50"></text></g><g><title>forward (torch/nn/modules/dropout.py:58) (9 samples, 0.30%)</title><rect x="52.8176%" y="404" width="0.3001%" height="15" fill="rgb(241,108,4)" fg:x="1584" fg:w="9"/><text x="53.0676%" y="414.50"></text></g><g><title>dropout (torch/nn/functional.py:1076) (8 samples, 0.27%)</title><rect x="52.8510%" y="420" width="0.2668%" height="15" fill="rgb(247,173,49)" fg:x="1585" fg:w="8"/><text x="53.1010%" y="430.50"></text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:216) (19 samples, 0.63%)</title><rect x="52.5175%" y="372" width="0.6335%" height="15" fill="rgb(224,114,35)" fg:x="1575" fg:w="19"/><text x="52.7675%" y="382.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:336) (226 samples, 7.54%)</title><rect x="46.6822%" y="356" width="7.5358%" height="15" fill="rgb(245,159,27)" fg:x="1400" fg:w="226"/><text x="46.9322%" y="366.50">forward (t..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:222) (32 samples, 1.07%)</title><rect x="53.1511%" y="372" width="1.0670%" height="15" fill="rgb(245,172,44)" fg:x="1594" fg:w="32"/><text x="53.4011%" y="382.50"></text></g><g><title>_merge_heads (transformers/models/gpt2/modeling_gpt2.py:291) (12 samples, 0.40%)</title><rect x="54.3515%" y="372" width="0.4001%" height="15" fill="rgb(236,23,11)" fg:x="1630" fg:w="12"/><text x="54.6015%" y="382.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:338) (19 samples, 0.63%)</title><rect x="54.2181%" y="356" width="0.6335%" height="15" fill="rgb(205,117,38)" fg:x="1626" fg:w="19"/><text x="54.4681%" y="366.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:886) (3 samples, 0.10%)</title><rect x="54.9517%" y="372" width="0.1000%" height="15" fill="rgb(237,72,25)" fg:x="1648" fg:w="3"/><text x="55.2017%" y="382.50"></text></g><g><title>forward (transformers/modeling_utils.py:2326) (4 samples, 0.13%)</title><rect x="55.0517%" y="388" width="0.1334%" height="15" fill="rgb(244,70,9)" fg:x="1651" fg:w="4"/><text x="55.3017%" y="398.50"></text></g><g><title>forward (transformers/modeling_utils.py:2327) (44 samples, 1.47%)</title><rect x="55.1851%" y="388" width="1.4672%" height="15" fill="rgb(217,125,39)" fg:x="1655" fg:w="44"/><text x="55.4351%" y="398.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:339) (58 samples, 1.93%)</title><rect x="54.8516%" y="356" width="1.9340%" height="15" fill="rgb(235,36,10)" fg:x="1645" fg:w="58"/><text x="55.1016%" y="366.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (52 samples, 1.73%)</title><rect x="55.0517%" y="372" width="1.7339%" height="15" fill="rgb(251,123,47)" fg:x="1651" fg:w="52"/><text x="55.3017%" y="382.50"></text></g><g><title>forward (transformers/modeling_utils.py:2328) (4 samples, 0.13%)</title><rect x="56.6522%" y="388" width="0.1334%" height="15" fill="rgb(221,13,13)" fg:x="1699" fg:w="4"/><text x="56.9022%" y="398.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:401) (423 samples, 14.10%)</title><rect x="42.8143%" y="324" width="14.1047%" height="15" fill="rgb(238,131,9)" fg:x="1284" fg:w="423"/><text x="43.0643%" y="334.50">forward (transformers..</text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (421 samples, 14.04%)</title><rect x="42.8810%" y="340" width="14.0380%" height="15" fill="rgb(211,50,8)" fg:x="1286" fg:w="421"/><text x="43.1310%" y="350.50">_call_impl (torch/nn/..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:340) (4 samples, 0.13%)</title><rect x="56.7856%" y="356" width="0.1334%" height="15" fill="rgb(245,182,24)" fg:x="1703" fg:w="4"/><text x="57.0356%" y="366.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:406) (20 samples, 0.67%)</title><rect x="56.9523%" y="324" width="0.6669%" height="15" fill="rgb(242,14,37)" fg:x="1708" fg:w="20"/><text x="57.2023%" y="334.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (27 samples, 0.90%)</title><rect x="57.8526%" y="340" width="0.9003%" height="15" fill="rgb(246,228,12)" fg:x="1735" fg:w="27"/><text x="58.1026%" y="350.50"></text></g><g><title>forward (torch/nn/modules/normalization.py:171) (26 samples, 0.87%)</title><rect x="57.8860%" y="356" width="0.8670%" height="15" fill="rgb(213,55,15)" fg:x="1736" fg:w="26"/><text x="58.1360%" y="366.50"></text></g><g><title>layer_norm (torch/nn/functional.py:2202) (25 samples, 0.83%)</title><rect x="57.9193%" y="372" width="0.8336%" height="15" fill="rgb(209,9,3)" fg:x="1737" fg:w="25"/><text x="58.1693%" y="382.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:431) (36 samples, 1.20%)</title><rect x="57.6192%" y="324" width="1.2004%" height="15" fill="rgb(230,59,30)" fg:x="1728" fg:w="36"/><text x="57.8692%" y="334.50"></text></g><g><title>forward (transformers/modeling_utils.py:2327) (32 samples, 1.07%)</title><rect x="59.1531%" y="388" width="1.0670%" height="15" fill="rgb(209,121,21)" fg:x="1774" fg:w="32"/><text x="59.4031%" y="398.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:359) (41 samples, 1.37%)</title><rect x="59.0197%" y="356" width="1.3671%" height="15" fill="rgb(220,109,13)" fg:x="1770" fg:w="41"/><text x="59.2697%" y="366.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (38 samples, 1.27%)</title><rect x="59.1197%" y="372" width="1.2671%" height="15" fill="rgb(232,18,1)" fg:x="1773" fg:w="38"/><text x="59.3697%" y="382.50"></text></g><g><title>forward (transformers/modeling_utils.py:2328) (5 samples, 0.17%)</title><rect x="60.2201%" y="388" width="0.1667%" height="15" fill="rgb(215,41,42)" fg:x="1806" fg:w="5"/><text x="60.4701%" y="398.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (109 samples, 3.63%)</title><rect x="60.4868%" y="372" width="3.6345%" height="15" fill="rgb(224,123,36)" fg:x="1814" fg:w="109"/><text x="60.7368%" y="382.50">_cal..</text></g><g><title>forward (transformers/activations.py:34) (109 samples, 3.63%)</title><rect x="60.4868%" y="388" width="3.6345%" height="15" fill="rgb(240,125,3)" fg:x="1814" fg:w="109"/><text x="60.7368%" y="398.50">forw..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:360) (115 samples, 3.83%)</title><rect x="60.3868%" y="356" width="3.8346%" height="15" fill="rgb(205,98,50)" fg:x="1811" fg:w="115"/><text x="60.6368%" y="366.50">forw..</text></g><g><title>_call_impl (torch/nn/modules/module.py:886) (3 samples, 0.10%)</title><rect x="64.4215%" y="372" width="0.1000%" height="15" fill="rgb(205,185,37)" fg:x="1932" fg:w="3"/><text x="64.6715%" y="382.50"></text></g><g><title>forward (transformers/modeling_utils.py:2327) (48 samples, 1.60%)</title><rect x="64.6215%" y="388" width="1.6005%" height="15" fill="rgb(238,207,15)" fg:x="1938" fg:w="48"/><text x="64.8715%" y="398.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (55 samples, 1.83%)</title><rect x="64.5215%" y="372" width="1.8339%" height="15" fill="rgb(213,199,42)" fg:x="1935" fg:w="55"/><text x="64.7715%" y="382.50">_..</text></g><g><title>forward (transformers/modeling_utils.py:2328) (4 samples, 0.13%)</title><rect x="66.2221%" y="388" width="0.1334%" height="15" fill="rgb(235,201,11)" fg:x="1986" fg:w="4"/><text x="66.4721%" y="398.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:361) (65 samples, 2.17%)</title><rect x="64.2214%" y="356" width="2.1674%" height="15" fill="rgb(207,46,11)" fg:x="1926" fg:w="65"/><text x="64.4714%" y="366.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (5 samples, 0.17%)</title><rect x="66.5889%" y="372" width="0.1667%" height="15" fill="rgb(241,35,35)" fg:x="1997" fg:w="5"/><text x="66.8389%" y="382.50"></text></g><g><title>forward (torch/nn/modules/dropout.py:58) (4 samples, 0.13%)</title><rect x="66.6222%" y="388" width="0.1334%" height="15" fill="rgb(243,32,47)" fg:x="1998" fg:w="4"/><text x="66.8722%" y="398.50"></text></g><g><title>dropout (torch/nn/functional.py:1076) (4 samples, 0.13%)</title><rect x="66.6222%" y="404" width="0.1334%" height="15" fill="rgb(247,202,23)" fg:x="1998" fg:w="4"/><text x="66.8722%" y="414.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:432) (239 samples, 7.97%)</title><rect x="58.8196%" y="324" width="7.9693%" height="15" fill="rgb(219,102,11)" fg:x="1764" fg:w="239"/><text x="59.0696%" y="334.50">forward (tr..</text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (234 samples, 7.80%)</title><rect x="58.9863%" y="340" width="7.8026%" height="15" fill="rgb(243,110,44)" fg:x="1769" fg:w="234"/><text x="59.2363%" y="350.50">_call_impl ..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:362) (12 samples, 0.40%)</title><rect x="66.3888%" y="356" width="0.4001%" height="15" fill="rgb(222,74,54)" fg:x="1991" fg:w="12"/><text x="66.6388%" y="366.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (780 samples, 26.01%)</title><rect x="41.3805%" y="308" width="26.0087%" height="15" fill="rgb(216,99,12)" fg:x="1241" fg:w="780"/><text x="41.6305%" y="318.50">_call_impl (torch/nn/modules/module.py:889)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:434) (18 samples, 0.60%)</title><rect x="66.7889%" y="324" width="0.6002%" height="15" fill="rgb(226,22,26)" fg:x="2003" fg:w="18"/><text x="67.0389%" y="334.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:898) (787 samples, 26.24%)</title><rect x="41.2471%" y="292" width="26.2421%" height="15" fill="rgb(217,163,10)" fg:x="1237" fg:w="787"/><text x="41.4971%" y="302.50">forward (transformers/models/gpt2/modeling..</text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (33 samples, 1.10%)</title><rect x="67.7893%" y="308" width="1.1004%" height="15" fill="rgb(213,25,53)" fg:x="2033" fg:w="33"/><text x="68.0393%" y="318.50"></text></g><g><title>forward (torch/nn/modules/normalization.py:171) (31 samples, 1.03%)</title><rect x="67.8560%" y="324" width="1.0337%" height="15" fill="rgb(252,105,26)" fg:x="2035" fg:w="31"/><text x="68.1060%" y="334.50"></text></g><g><title>layer_norm (torch/nn/functional.py:2202) (29 samples, 0.97%)</title><rect x="67.9226%" y="340" width="0.9670%" height="15" fill="rgb(220,39,43)" fg:x="2037" fg:w="29"/><text x="68.1726%" y="350.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:916) (43 samples, 1.43%)</title><rect x="67.5225%" y="292" width="1.4338%" height="15" fill="rgb(229,68,48)" fg:x="2025" fg:w="43"/><text x="67.7725%" y="302.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:918) (4 samples, 0.13%)</title><rect x="68.9563%" y="292" width="0.1334%" height="15" fill="rgb(252,8,32)" fg:x="2068" fg:w="4"/><text x="69.2063%" y="302.50"></text></g><g><title>__post_init__ (transformers/utils/generic.py:161) (3 samples, 0.10%)</title><rect x="69.3565%" y="324" width="0.1000%" height="15" fill="rgb(223,20,43)" fg:x="2080" fg:w="3"/><text x="69.6065%" y="334.50"></text></g><g><title>fields (dataclasses.py:1028) (3 samples, 0.10%)</title><rect x="69.3565%" y="340" width="0.1000%" height="15" fill="rgb(229,81,49)" fg:x="2080" fg:w="3"/><text x="69.6065%" y="350.50"></text></g><g><title>__post_init__ (transformers/utils/generic.py:166) (4 samples, 0.13%)</title><rect x="69.4898%" y="324" width="0.1334%" height="15" fill="rgb(236,28,36)" fg:x="2084" fg:w="4"/><text x="69.7398%" y="334.50"></text></g><g><title>__post_init__ (transformers/utils/generic.py:170) (3 samples, 0.10%)</title><rect x="69.6566%" y="324" width="0.1000%" height="15" fill="rgb(249,185,26)" fg:x="2089" fg:w="3"/><text x="69.9066%" y="334.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (1,079 samples, 35.98%)</title><rect x="33.9113%" y="276" width="35.9787%" height="15" fill="rgb(249,174,33)" fg:x="1017" fg:w="1079"/><text x="34.1613%" y="286.50">_call_impl (torch/nn/modules/module.py:889)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:935) (24 samples, 0.80%)</title><rect x="69.0897%" y="292" width="0.8003%" height="15" fill="rgb(233,201,37)" fg:x="2072" fg:w="24"/><text x="69.3397%" y="302.50"></text></g><g><title>__init__ (&lt;string&gt;:8) (18 samples, 0.60%)</title><rect x="69.2898%" y="308" width="0.6002%" height="15" fill="rgb(221,78,26)" fg:x="2078" fg:w="18"/><text x="69.5398%" y="318.50"></text></g><g><title>__post_init__ (transformers/utils/generic.py:202) (4 samples, 0.13%)</title><rect x="69.7566%" y="324" width="0.1334%" height="15" fill="rgb(250,127,30)" fg:x="2092" fg:w="4"/><text x="70.0066%" y="334.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1060) (1,087 samples, 36.25%)</title><rect x="33.7112%" y="260" width="36.2454%" height="15" fill="rgb(230,49,44)" fg:x="1011" fg:w="1087"/><text x="33.9612%" y="270.50">forward (transformers/models/gpt2/modeling_gpt2.py:1060)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1062) (8 samples, 0.27%)</title><rect x="69.9567%" y="260" width="0.2668%" height="15" fill="rgb(229,67,23)" fg:x="2098" fg:w="8"/><text x="70.2067%" y="270.50"></text></g><g><title>__getitem__ (transformers/utils/generic.py:221) (8 samples, 0.27%)</title><rect x="69.9567%" y="276" width="0.2668%" height="15" fill="rgb(249,83,47)" fg:x="2098" fg:w="8"/><text x="70.2067%" y="286.50"></text></g><g><title>to_tuple (transformers/utils/generic.py:239) (7 samples, 0.23%)</title><rect x="69.9900%" y="292" width="0.2334%" height="15" fill="rgb(215,43,3)" fg:x="2099" fg:w="7"/><text x="70.2400%" y="302.50"></text></g><g><title>&lt;genexpr&gt; (transformers/utils/generic.py:239) (4 samples, 0.13%)</title><rect x="70.0900%" y="308" width="0.1334%" height="15" fill="rgb(238,154,13)" fg:x="2102" fg:w="4"/><text x="70.3400%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (45 samples, 1.50%)</title><rect x="70.3901%" y="276" width="1.5005%" height="15" fill="rgb(219,56,2)" fg:x="2111" fg:w="45"/><text x="70.6401%" y="286.50"></text></g><g><title>forward (torch/nn/modules/linear.py:94) (45 samples, 1.50%)</title><rect x="70.3901%" y="292" width="1.5005%" height="15" fill="rgb(233,0,4)" fg:x="2111" fg:w="45"/><text x="70.6401%" y="302.50"></text></g><g><title>linear (torch/nn/functional.py:1753) (39 samples, 1.30%)</title><rect x="70.5902%" y="308" width="1.3004%" height="15" fill="rgb(235,30,7)" fg:x="2117" fg:w="39"/><text x="70.8402%" y="318.50"></text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1069) (54 samples, 1.80%)</title><rect x="70.2234%" y="260" width="1.8006%" height="15" fill="rgb(250,79,13)" fg:x="2106" fg:w="54"/><text x="70.4734%" y="270.50">f..</text></g><g><title>__post_init__ (transformers/utils/generic.py:161) (3 samples, 0.10%)</title><rect x="72.2574%" y="292" width="0.1000%" height="15" fill="rgb(211,146,34)" fg:x="2167" fg:w="3"/><text x="72.5074%" y="302.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (1,178 samples, 39.28%)</title><rect x="33.2444%" y="212" width="39.2798%" height="15" fill="rgb(228,22,38)" fg:x="997" fg:w="1178"/><text x="33.4944%" y="222.50">_call_impl (torch/nn/modules/module.py:889)</text></g><g><title>forward (deepspeed/inference/engine.py:572) (1,175 samples, 39.18%)</title><rect x="33.3444%" y="228" width="39.1797%" height="15" fill="rgb(235,168,5)" fg:x="1000" fg:w="1175"/><text x="33.5944%" y="238.50">forward (deepspeed/inference/engine.py:572)</text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (1,168 samples, 38.95%)</title><rect x="33.5779%" y="244" width="38.9463%" height="15" fill="rgb(221,155,16)" fg:x="1007" fg:w="1168"/><text x="33.8279%" y="254.50">_call_impl (torch/nn/modules/module.py:889)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1090) (15 samples, 0.50%)</title><rect x="72.0240%" y="260" width="0.5002%" height="15" fill="rgb(215,215,53)" fg:x="2160" fg:w="15"/><text x="72.2740%" y="270.50"></text></g><g><title>__init__ (&lt;string&gt;:9) (9 samples, 0.30%)</title><rect x="72.2241%" y="276" width="0.3001%" height="15" fill="rgb(223,4,10)" fg:x="2166" fg:w="9"/><text x="72.4741%" y="286.50"></text></g><g><title>generate_stream (generator.py:580) (1,958 samples, 65.29%)</title><rect x="7.2691%" y="148" width="65.2884%" height="15" fill="rgb(234,103,6)" fg:x="218" fg:w="1958"/><text x="7.5191%" y="158.50">generate_stream (generator.py:580)</text></g><g><title>call_model (generator.py:483) (1,951 samples, 65.06%)</title><rect x="7.5025%" y="164" width="65.0550%" height="15" fill="rgb(227,97,0)" fg:x="225" fg:w="1951"/><text x="7.7525%" y="174.50">call_model (generator.py:483)</text></g><g><title>_call_impl (torch/nn/modules/module.py:889) (1,945 samples, 64.85%)</title><rect x="7.7026%" y="180" width="64.8550%" height="15" fill="rgb(234,150,53)" fg:x="231" fg:w="1945"/><text x="7.9526%" y="190.50">_call_impl (torch/nn/modules/module.py:889)</text></g><g><title>forward (wrapper.py:73) (1,191 samples, 39.71%)</title><rect x="32.8443%" y="196" width="39.7132%" height="15" fill="rgb(228,201,54)" fg:x="985" fg:w="1191"/><text x="33.0943%" y="206.50">forward (wrapper.py:73)</text></g><g><title>generate_stream (generator.py:583) (5 samples, 0.17%)</title><rect x="72.5909%" y="148" width="0.1667%" height="15" fill="rgb(222,22,37)" fg:x="2177" fg:w="5"/><text x="72.8409%" y="158.50"></text></g><g><title>generate_stream (generator.py:594) (20 samples, 0.67%)</title><rect x="72.7576%" y="148" width="0.6669%" height="15" fill="rgb(237,53,32)" fg:x="2182" fg:w="20"/><text x="73.0076%" y="158.50"></text></g><g><title>generate_stream (generator.py:636) (18 samples, 0.60%)</title><rect x="73.4578%" y="148" width="0.6002%" height="15" fill="rgb(233,25,53)" fg:x="2203" fg:w="18"/><text x="73.7078%" y="158.50"></text></g><g><title>search_next (generator.py:789) (14 samples, 0.47%)</title><rect x="74.5248%" y="164" width="0.4668%" height="15" fill="rgb(210,40,34)" fg:x="2235" fg:w="14"/><text x="74.7748%" y="174.50"></text></g><g><title>log_softmax (torch/nn/functional.py:1672) (13 samples, 0.43%)</title><rect x="74.5582%" y="180" width="0.4335%" height="15" fill="rgb(241,220,44)" fg:x="2236" fg:w="13"/><text x="74.8082%" y="190.50"></text></g><g><title>search_next (generator.py:807) (10 samples, 0.33%)</title><rect x="74.9917%" y="164" width="0.3334%" height="15" fill="rgb(235,28,35)" fg:x="2249" fg:w="10"/><text x="75.2417%" y="174.50"></text></g><g><title>search_next (generator.py:809) (3 samples, 0.10%)</title><rect x="75.3251%" y="164" width="0.1000%" height="15" fill="rgb(210,56,17)" fg:x="2259" fg:w="3"/><text x="75.5751%" y="174.50"></text></g><g><title>search_next (generator.py:866) (61 samples, 2.03%)</title><rect x="75.4251%" y="164" width="2.0340%" height="15" fill="rgb(224,130,29)" fg:x="2262" fg:w="61"/><text x="75.6751%" y="174.50">s..</text></g><g><title>search_next (generator.py:868) (46 samples, 1.53%)</title><rect x="77.4592%" y="164" width="1.5338%" height="15" fill="rgb(235,212,8)" fg:x="2323" fg:w="46"/><text x="77.7092%" y="174.50"></text></g><g><title>search_next (generator.py:876) (12 samples, 0.40%)</title><rect x="79.0263%" y="164" width="0.4001%" height="15" fill="rgb(223,33,50)" fg:x="2370" fg:w="12"/><text x="79.2763%" y="174.50"></text></g><g><title>search_next (generator.py:877) (39 samples, 1.30%)</title><rect x="79.4265%" y="164" width="1.3004%" height="15" fill="rgb(219,149,13)" fg:x="2382" fg:w="39"/><text x="79.6765%" y="174.50"></text></g><g><title>__rsub__ (torch/tensor.py:528) (20 samples, 0.67%)</title><rect x="80.0600%" y="180" width="0.6669%" height="15" fill="rgb(250,156,29)" fg:x="2401" fg:w="20"/><text x="80.3100%" y="190.50"></text></g><g><title>search_next (generator.py:878) (21 samples, 0.70%)</title><rect x="80.7269%" y="164" width="0.7002%" height="15" fill="rgb(216,193,19)" fg:x="2421" fg:w="21"/><text x="80.9769%" y="174.50"></text></g><g><title>search_next (generator.py:879) (18 samples, 0.60%)</title><rect x="81.4271%" y="164" width="0.6002%" height="15" fill="rgb(216,135,14)" fg:x="2442" fg:w="18"/><text x="81.6771%" y="174.50"></text></g><g><title>search_next (generator.py:881) (13 samples, 0.43%)</title><rect x="82.0273%" y="164" width="0.4335%" height="15" fill="rgb(241,47,5)" fg:x="2460" fg:w="13"/><text x="82.2773%" y="174.50"></text></g><g><title>search_next (generator.py:884) (3 samples, 0.10%)</title><rect x="82.4608%" y="164" width="0.1000%" height="15" fill="rgb(233,42,35)" fg:x="2473" fg:w="3"/><text x="82.7108%" y="174.50"></text></g><g><title>search_next (generator.py:892) (22 samples, 0.73%)</title><rect x="82.7276%" y="164" width="0.7336%" height="15" fill="rgb(231,13,6)" fg:x="2481" fg:w="22"/><text x="82.9776%" y="174.50"></text></g><g><title>search_next (generator.py:895) (25 samples, 0.83%)</title><rect x="83.4612%" y="164" width="0.8336%" height="15" fill="rgb(207,181,40)" fg:x="2503" fg:w="25"/><text x="83.7112%" y="174.50"></text></g><g><title>wrapped (torch/tensor.py:29) (21 samples, 0.70%)</title><rect x="83.5945%" y="180" width="0.7002%" height="15" fill="rgb(254,173,49)" fg:x="2507" fg:w="21"/><text x="83.8445%" y="190.50"></text></g><g><title>__floordiv__ (torch/tensor.py:559) (21 samples, 0.70%)</title><rect x="83.5945%" y="196" width="0.7002%" height="15" fill="rgb(221,1,38)" fg:x="2507" fg:w="21"/><text x="83.8445%" y="206.50"></text></g><g><title>search_next (generator.py:896) (21 samples, 0.70%)</title><rect x="84.2948%" y="164" width="0.7002%" height="15" fill="rgb(206,124,46)" fg:x="2528" fg:w="21"/><text x="84.5448%" y="174.50"></text></g><g><title>search_next (generator.py:900) (5 samples, 0.17%)</title><rect x="84.9950%" y="164" width="0.1667%" height="15" fill="rgb(249,21,11)" fg:x="2549" fg:w="5"/><text x="85.2450%" y="174.50"></text></g><g><title>search_next (generator.py:901) (41 samples, 1.37%)</title><rect x="85.1617%" y="164" width="1.3671%" height="15" fill="rgb(222,201,40)" fg:x="2554" fg:w="41"/><text x="85.4117%" y="174.50"></text></g><g><title>search_next (generator.py:913) (9 samples, 0.30%)</title><rect x="86.5288%" y="164" width="0.3001%" height="15" fill="rgb(235,61,29)" fg:x="2595" fg:w="9"/><text x="86.7788%" y="174.50"></text></g><g><title>search_next (generator.py:917) (8 samples, 0.27%)</title><rect x="86.8623%" y="164" width="0.2668%" height="15" fill="rgb(219,207,3)" fg:x="2605" fg:w="8"/><text x="87.1123%" y="174.50"></text></g><g><title>__rsub__ (torch/tensor.py:528) (20 samples, 0.67%)</title><rect x="88.0293%" y="180" width="0.6669%" height="15" fill="rgb(222,56,46)" fg:x="2640" fg:w="20"/><text x="88.2793%" y="190.50"></text></g><g><title>search_next (generator.py:918) (48 samples, 1.60%)</title><rect x="87.1290%" y="164" width="1.6005%" height="15" fill="rgb(239,76,54)" fg:x="2613" fg:w="48"/><text x="87.3790%" y="174.50"></text></g><g><title>search_next (generator.py:925) (24 samples, 0.80%)</title><rect x="88.8296%" y="164" width="0.8003%" height="15" fill="rgb(231,124,27)" fg:x="2664" fg:w="24"/><text x="89.0796%" y="174.50"></text></g><g><title>search_next (generator.py:932) (38 samples, 1.27%)</title><rect x="89.6632%" y="164" width="1.2671%" height="15" fill="rgb(249,195,6)" fg:x="2689" fg:w="38"/><text x="89.9132%" y="174.50"></text></g><g><title>search_next (generator.py:937) (53 samples, 1.77%)</title><rect x="90.9303%" y="164" width="1.7673%" height="15" fill="rgb(237,174,47)" fg:x="2727" fg:w="53"/><text x="91.1803%" y="174.50"></text></g><g><title>generate_stream (generator.py:662) (558 samples, 18.61%)</title><rect x="74.1581%" y="148" width="18.6062%" height="15" fill="rgb(206,201,31)" fg:x="2224" fg:w="558"/><text x="74.4081%" y="158.50">generate_stream (generator.py..</text></g><g><title>generate_stream (generator.py:673) (97 samples, 3.23%)</title><rect x="92.7976%" y="148" width="3.2344%" height="15" fill="rgb(231,57,52)" fg:x="2783" fg:w="97"/><text x="93.0476%" y="158.50">gen..</text></g><g><title>generate_stream (generator.py:674) (3 samples, 0.10%)</title><rect x="96.0320%" y="148" width="0.1000%" height="15" fill="rgb(248,177,22)" fg:x="2880" fg:w="3"/><text x="96.2820%" y="158.50"></text></g><g><title>generate (generator.py:436) (2,709 samples, 90.33%)</title><rect x="5.8353%" y="132" width="90.3301%" height="15" fill="rgb(215,211,37)" fg:x="175" fg:w="2709"/><text x="6.0853%" y="142.50">generate (generator.py:436)</text></g><g><title>run_generation (deepspeed_inference.py:148) (2,715 samples, 90.53%)</title><rect x="5.7686%" y="116" width="90.5302%" height="15" fill="rgb(241,128,51)" fg:x="173" fg:w="2715"/><text x="6.0186%" y="126.50">run_generation (deepspeed_inference.py:148)</text></g><g><title>process_results (deepspeed_inference.py:43) (4 samples, 0.13%)</title><rect x="96.2988%" y="132" width="0.1334%" height="15" fill="rgb(227,165,31)" fg:x="2888" fg:w="4"/><text x="96.5488%" y="142.50"></text></g><g><title>process_results (deepspeed_inference.py:45) (4 samples, 0.13%)</title><rect x="96.4321%" y="132" width="0.1334%" height="15" fill="rgb(228,167,24)" fg:x="2892" fg:w="4"/><text x="96.6821%" y="142.50"></text></g><g><title>process_results (deepspeed_inference.py:54) (17 samples, 0.57%)</title><rect x="96.6322%" y="132" width="0.5669%" height="15" fill="rgb(228,143,12)" fg:x="2898" fg:w="17"/><text x="96.8822%" y="142.50"></text></g><g><title>eos_token_id (transformers/tokenization_utils_base.py:1084) (11 samples, 0.37%)</title><rect x="96.8323%" y="148" width="0.3668%" height="15" fill="rgb(249,149,8)" fg:x="2904" fg:w="11"/><text x="97.0823%" y="158.50"></text></g><g><title>convert_tokens_to_ids (transformers/tokenization_utils.py:574) (6 samples, 0.20%)</title><rect x="96.9990%" y="164" width="0.2001%" height="15" fill="rgb(243,35,44)" fg:x="2909" fg:w="6"/><text x="97.2490%" y="174.50"></text></g><g><title>_convert_token_to_id_with_added_voc (transformers/tokenization_utils.py:587) (4 samples, 0.13%)</title><rect x="97.0657%" y="180" width="0.1334%" height="15" fill="rgb(246,89,9)" fg:x="2911" fg:w="4"/><text x="97.3157%" y="190.50"></text></g><g><title>_convert_token_to_id (transformers/models/gpt2/tokenization_gpt2.py:257) (3 samples, 0.10%)</title><rect x="97.0990%" y="196" width="0.1000%" height="15" fill="rgb(233,213,13)" fg:x="2912" fg:w="3"/><text x="97.3490%" y="206.50"></text></g><g><title>convert_tokens_to_ids (transformers/tokenization_utils.py:574) (11 samples, 0.37%)</title><rect x="97.4658%" y="180" width="0.3668%" height="15" fill="rgb(233,141,41)" fg:x="2923" fg:w="11"/><text x="97.7158%" y="190.50"></text></g><g><title>_convert_token_to_id_with_added_voc (transformers/tokenization_utils.py:587) (9 samples, 0.30%)</title><rect x="97.5325%" y="196" width="0.3001%" height="15" fill="rgb(239,167,4)" fg:x="2925" fg:w="9"/><text x="97.7825%" y="206.50"></text></g><g><title>_convert_token_to_id (transformers/models/gpt2/tokenization_gpt2.py:257) (6 samples, 0.20%)</title><rect x="97.6325%" y="212" width="0.2001%" height="15" fill="rgb(209,217,16)" fg:x="2928" fg:w="6"/><text x="97.8825%" y="222.50"></text></g><g><title>process_results (deepspeed_inference.py:59) (19 samples, 0.63%)</title><rect x="97.2324%" y="132" width="0.6335%" height="15" fill="rgb(219,88,35)" fg:x="2916" fg:w="19"/><text x="97.4824%" y="142.50"></text></g><g><title>&lt;listcomp&gt; (deepspeed_inference.py:59) (18 samples, 0.60%)</title><rect x="97.2658%" y="148" width="0.6002%" height="15" fill="rgb(220,193,23)" fg:x="2917" fg:w="18"/><text x="97.5158%" y="158.50"></text></g><g><title>eos_token_id (transformers/tokenization_utils_base.py:1084) (16 samples, 0.53%)</title><rect x="97.3324%" y="164" width="0.5335%" height="15" fill="rgb(230,90,52)" fg:x="2919" fg:w="16"/><text x="97.5824%" y="174.50"></text></g><g><title>to_py_obj (transformers/utils/generic.py:118) (3 samples, 0.10%)</title><rect x="98.1327%" y="196" width="0.1000%" height="15" fill="rgb(252,106,19)" fg:x="2943" fg:w="3"/><text x="98.3827%" y="206.50"></text></g><g><title>_is_torch (transformers/utils/generic.py:85) (3 samples, 0.10%)</title><rect x="98.1327%" y="212" width="0.1000%" height="15" fill="rgb(206,74,20)" fg:x="2943" fg:w="3"/><text x="98.3827%" y="222.50"></text></g><g><title>decode (transformers/tokenization_utils_base.py:3302) (13 samples, 0.43%)</title><rect x="97.8993%" y="148" width="0.4335%" height="15" fill="rgb(230,138,44)" fg:x="2936" fg:w="13"/><text x="98.1493%" y="158.50"></text></g><g><title>to_py_obj (transformers/utils/generic.py:115) (12 samples, 0.40%)</title><rect x="97.9326%" y="164" width="0.4001%" height="15" fill="rgb(235,182,43)" fg:x="2937" fg:w="12"/><text x="98.1826%" y="174.50"></text></g><g><title>&lt;listcomp&gt; (transformers/utils/generic.py:115) (11 samples, 0.37%)</title><rect x="97.9660%" y="180" width="0.3668%" height="15" fill="rgb(242,16,51)" fg:x="2938" fg:w="11"/><text x="98.2160%" y="190.50"></text></g><g><title>to_py_obj (transformers/utils/generic.py:122) (3 samples, 0.10%)</title><rect x="98.2327%" y="196" width="0.1000%" height="15" fill="rgb(248,9,4)" fg:x="2946" fg:w="3"/><text x="98.4827%" y="206.50"></text></g><g><title>_decode (transformers/tokenization_utils.py:928) (7 samples, 0.23%)</title><rect x="98.3995%" y="164" width="0.2334%" height="15" fill="rgb(210,31,22)" fg:x="2951" fg:w="7"/><text x="98.6495%" y="174.50"></text></g><g><title>convert_ids_to_tokens (transformers/tokenization_utils.py:909) (5 samples, 0.17%)</title><rect x="98.4662%" y="180" width="0.1667%" height="15" fill="rgb(239,54,39)" fg:x="2953" fg:w="5"/><text x="98.7162%" y="190.50"></text></g><g><title>_convert_id_to_token (transformers/models/gpt2/tokenization_gpt2.py:261) (3 samples, 0.10%)</title><rect x="98.5328%" y="196" width="0.1000%" height="15" fill="rgb(230,99,41)" fg:x="2955" fg:w="3"/><text x="98.7828%" y="206.50"></text></g><g><title>_decode (transformers/tokenization_utils.py:946) (7 samples, 0.23%)</title><rect x="98.6662%" y="164" width="0.2334%" height="15" fill="rgb(253,106,12)" fg:x="2959" fg:w="7"/><text x="98.9162%" y="174.50"></text></g><g><title>convert_tokens_to_string (transformers/models/gpt2/tokenization_gpt2.py:266) (6 samples, 0.20%)</title><rect x="98.6996%" y="180" width="0.2001%" height="15" fill="rgb(213,46,41)" fg:x="2960" fg:w="6"/><text x="98.9496%" y="190.50"></text></g><g><title>&lt;listcomp&gt; (transformers/models/gpt2/tokenization_gpt2.py:266) (4 samples, 0.13%)</title><rect x="98.7663%" y="196" width="0.1334%" height="15" fill="rgb(215,133,35)" fg:x="2962" fg:w="4"/><text x="99.0163%" y="206.50"></text></g><g><title>Eval (model.py:319) (2,955 samples, 98.53%)</title><rect x="0.4001%" y="100" width="98.5328%" height="15" fill="rgb(213,28,5)" fg:x="12" fg:w="2955"/><text x="0.6501%" y="110.50">Eval (model.py:319)</text></g><g><title>run_generation (deepspeed_inference.py:163) (79 samples, 2.63%)</title><rect x="96.2988%" y="116" width="2.6342%" height="15" fill="rgb(215,77,49)" fg:x="2888" fg:w="79"/><text x="96.5488%" y="126.50">ru..</text></g><g><title>process_results (deepspeed_inference.py:61) (32 samples, 1.07%)</title><rect x="97.8660%" y="132" width="1.0670%" height="15" fill="rgb(248,100,22)" fg:x="2935" fg:w="32"/><text x="98.1160%" y="142.50"></text></g><g><title>decode (transformers/tokenization_utils_base.py:3308) (17 samples, 0.57%)</title><rect x="98.3661%" y="148" width="0.5669%" height="15" fill="rgb(208,67,9)" fg:x="2950" fg:w="17"/><text x="98.6161%" y="158.50"></text></g><g><title>generate_ngrams (model.py:177) (5 samples, 0.17%)</title><rect x="99.1664%" y="148" width="0.1667%" height="15" fill="rgb(219,133,21)" fg:x="2974" fg:w="5"/><text x="99.4164%" y="158.50"></text></g><g><title>is_adult_query (model.py:216) (12 samples, 0.40%)</title><rect x="99.0997%" y="132" width="0.4001%" height="15" fill="rgb(246,46,29)" fg:x="2972" fg:w="12"/><text x="99.3497%" y="142.50"></text></g><g><title>generate_ngrams (model.py:178) (5 samples, 0.17%)</title><rect x="99.3331%" y="148" width="0.1667%" height="15" fill="rgb(246,185,52)" fg:x="2979" fg:w="5"/><text x="99.5831%" y="158.50"></text></g><g><title>&lt;listcomp&gt; (model.py:178) (3 samples, 0.10%)</title><rect x="99.3998%" y="164" width="0.1000%" height="15" fill="rgb(252,136,11)" fg:x="2981" fg:w="3"/><text x="99.6498%" y="174.50"></text></g><g><title>filter_suggestions (model.py:242) (16 samples, 0.53%)</title><rect x="99.0664%" y="116" width="0.5335%" height="15" fill="rgb(219,138,53)" fg:x="2971" fg:w="16"/><text x="99.3164%" y="126.50"></text></g><g><title>filter_suggestions (model.py:244) (5 samples, 0.17%)</title><rect x="99.5999%" y="116" width="0.1667%" height="15" fill="rgb(211,51,23)" fg:x="2987" fg:w="5"/><text x="99.8499%" y="126.50"></text></g><g><title>match (re.py:175) (4 samples, 0.13%)</title><rect x="99.6332%" y="132" width="0.1334%" height="15" fill="rgb(247,221,28)" fg:x="2988" fg:w="4"/><text x="99.8832%" y="142.50"></text></g><g><title>Eval (model.py:321) (29 samples, 0.97%)</title><rect x="98.9330%" y="100" width="0.9670%" height="15" fill="rgb(251,222,45)" fg:x="2967" fg:w="29"/><text x="99.1830%" y="110.50"></text></g><g><title>process (offline_process.py:27) (2,996 samples, 99.90%)</title><rect x="0.0333%" y="84" width="99.9000%" height="15" fill="rgb(217,162,53)" fg:x="1" fg:w="2996"/><text x="0.2833%" y="94.50">process (offline_process.py:27)</text></g><g><title>all (2,999 samples, 100%)</title><rect x="0.0000%" y="52" width="100.0000%" height="15" fill="rgb(229,93,14)" fg:x="0" fg:w="2999"/><text x="0.2500%" y="62.50"></text></g><g><title>&lt;module&gt; (offline_process.py:71) (2,999 samples, 100.00%)</title><rect x="0.0000%" y="68" width="100.0000%" height="15" fill="rgb(209,67,49)" fg:x="0" fg:w="2999"/><text x="0.2500%" y="78.50">&lt;module&gt; (offline_process.py:71)</text></g></svg></svg>